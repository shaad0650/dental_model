{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13581064,"sourceType":"datasetVersion","datasetId":8628331}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install numpy==1.26.4 scipy==1.12.0 scikit-learn==1.3.2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom dataclasses import dataclass\nimport os, random, json\nimport numpy as np\nimport torch\n\n@dataclass\nclass CFG:\n    data_dir: str = \"/kaggle/input/dental-dataset/A DENTAL INTRAORAL IMAGE DATASET OF GINGIVITIS FOR IMAGE CAPTIONING/Dataset/Dataset/Training\"\n    output_dir: str = \"/kaggle/working/gingivitis-model\"\n    classes: tuple = (\"healthy\", \"mild\", \"severe\")\n    \n    # Keep it simple\n    img_size: int = 384\n    backbone: str = \"resnet50\" \n    \n    batch_size: int = 16\n    epochs: int = 100\n\n    lr: float = 1e-4  \n    weight_decay: float = 0.01\n    \n  \n    use_class_weights: bool = False\n    label_smoothing: float = 0.0  \n    \n    dropout: float = 0.2\n    num_workers: int = 2\n    seed: int = 42\n    \n\n    patience: int = 15\n    \n   \n    use_weighted_sampler: bool = False\n\ncfg = CFG()\nos.makedirs(cfg.output_dir, exist_ok=True)\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(cfg.seed)\nprint(\"‚úÖ Simple configuration loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:10.570149Z","iopub.execute_input":"2025-11-02T12:09:10.570396Z","iopub.status.idle":"2025-11-02T12:09:12.113320Z","shell.execute_reply.started":"2025-11-02T12:09:10.570379Z","shell.execute_reply":"2025-11-02T12:09:12.112425Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Simple configuration loaded\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nimport pandas as pd\nimport glob\nimport os\n\nIMG_DIR = os.path.join(cfg.data_dir, \"Images\")\nLBL_DIR = os.path.join(cfg.data_dir, \"Labels\")\n\ndef get_label_from_txt(txt_path):\n    cls_ids = []\n    with open(txt_path, \"r\") as f:\n        for line in f:\n            if line.strip():\n                cls = int(line.split()[0])\n                cls_ids.append(cls)\n\n    if len(cls_ids) == 0:\n        return None\n\n    if 5 in cls_ids:\n        return \"severe\"\n    if 3 in cls_ids or 4 in cls_ids:\n        return \"mild\"\n    return \"healthy\"\n\n\nimage_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*.jpg\")))\nrows = []\n\nfor img_path in image_paths:\n    base = os.path.basename(img_path).replace(\".jpg\", \"\")\n    lbl_path = os.path.join(LBL_DIR, base + \".txt\")\n\n    if not os.path.exists(lbl_path):\n        print(f\"‚ö†Ô∏è Missing label for: {base}.jpg\")\n        continue\n\n    cls = get_label_from_txt(lbl_path)\n    if cls is None:\n        print(f\"‚ö†Ô∏è Empty or invalid label in: {base}.txt\")\n        continue\n\n    rows.append({\"path\": img_path, \"label\": cls})\n\n\ndf = pd.DataFrame(rows)\n\nif \"label\" not in df.columns or len(df) == 0:\n    raise ValueError(\"‚ùå No valid labeled data found! Check your dataset paths or label file format.\")\n\n\nlabel2id = {\"healthy\": 0, \"mild\": 1, \"severe\": 2}\ndf[\"label_id\"] = df[\"label\"].map(label2id)\n\n\nprint(\"‚úÖ Dataset Loaded Successfully!\\n\")\nprint(\"üìä Dataset Distribution:\")\nprint(df[\"label\"].value_counts())\n\nprint(\"\\n‚ö†Ô∏è Check if distribution is balanced enough:\")\nfor cls in cfg.classes:\n    count = (df[\"label\"] == cls).sum()\n    pct = count / len(df) * 100\n    print(f\"  {cls}: {count} ({pct:.1f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:14.811334Z","iopub.execute_input":"2025-11-02T12:09:14.812138Z","iopub.status.idle":"2025-11-02T12:09:17.088733Z","shell.execute_reply.started":"2025-11-02T12:09:14.812112Z","shell.execute_reply":"2025-11-02T12:09:17.087885Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset Loaded Successfully!\n\nüìä Dataset Distribution:\nlabel\nsevere     614\nmild       106\nhealthy     12\nName: count, dtype: int64\n\n‚ö†Ô∏è Check if distribution is balanced enough:\n  healthy: 12 (1.6%)\n  mild: 106 (14.5%)\n  severe: 614 (83.9%)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\n\nclass_counts = df['label'].value_counts()\nmin_count = class_counts.min()\nmax_count = class_counts.max()\nimbalance_ratio = max_count / min_count\n\nprint(f\"\\nImbalance ratio: {imbalance_ratio:.2f}x\")\n\nif imbalance_ratio > 3.0:\n    print(\"‚ö†Ô∏è SEVERE IMBALANCE DETECTED - Applying data augmentation strategy\")\n    \n    # Find minority classes\n    majority_class = class_counts.idxmax()\n    target_count = int(class_counts.max() * 0.7)  \n    \n    augmented_rows = []\n    for cls in cfg.classes:\n        cls_df = df[df['label'] == cls]\n        current_count = len(cls_df)\n        \n        if current_count < target_count:\n            # Duplicate minority class samples\n            multiplier = int(np.ceil(target_count / current_count))\n            print(f\"  Augmenting {cls}: {current_count} -> {current_count * multiplier} samples\")\n            for _ in range(multiplier - 1):\n                augmented_rows.append(cls_df)\n        \n        augmented_rows.append(cls_df)\n    \n    df_balanced = pd.concat(augmented_rows, ignore_index=True)\n    df_balanced = df_balanced.sample(frac=1, random_state=cfg.seed).reset_index(drop=True)\n    \n    print(f\"\\nBalanced dataset:\")\n    print(df_balanced['label'].value_counts())\n    df = df_balanced\nelse:\n    print(\"‚úÖ Dataset reasonably balanced\")\n\n\ntrain_df, temp_df = train_test_split(\n    df, test_size=0.30, stratify=df[\"label_id\"], random_state=cfg.seed\n)\nval_df, test_df = train_test_split(\n    temp_df, test_size=0.50, stratify=temp_df[\"label_id\"], random_state=cfg.seed\n)\n\nprint(\"\\nSplit Distribution:\")\nprint(\"Train:\", dict(train_df['label'].value_counts()))\nprint(\"Val:\", dict(val_df['label'].value_counts()))\nprint(\"Test:\", dict(test_df['label'].value_counts()))\n\ntrain_df.to_csv(os.path.join(cfg.output_dir, \"train.csv\"), index=False)\nval_df.to_csv(os.path.join(cfg.output_dir, \"val.csv\"), index=False)\ntest_df.to_csv(os.path.join(cfg.output_dir, \"test.csv\"), index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:20.892417Z","iopub.execute_input":"2025-11-02T12:09:20.892857Z","iopub.status.idle":"2025-11-02T12:09:21.343508Z","shell.execute_reply.started":"2025-11-02T12:09:20.892832Z","shell.execute_reply":"2025-11-02T12:09:21.342656Z"}},"outputs":[{"name":"stdout","text":"\nImbalance ratio: 51.17x\n‚ö†Ô∏è SEVERE IMBALANCE DETECTED - Applying data augmentation strategy\n  Augmenting healthy: 12 -> 432 samples\n  Augmenting mild: 106 -> 530 samples\n\nBalanced dataset:\nlabel\nsevere     614\nmild       530\nhealthy    432\nName: count, dtype: int64\n\nSplit Distribution:\nTrain: {'severe': 430, 'mild': 371, 'healthy': 302}\nVal: {'severe': 92, 'mild': 79, 'healthy': 65}\nTest: {'severe': 92, 'mild': 80, 'healthy': 65}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_transforms(split=\"train\"):\n    \"\"\"Start with minimal augmentation to see if model CAN learn\"\"\"\n    if split == \"train\":\n        return A.Compose([\n            A.Resize(cfg.img_size, cfg.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n        ])\n    else:\n        return A.Compose([\n            A.Resize(cfg.img_size, cfg.img_size),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n        ])\n\nprint(\"‚úÖ Minimal augmentation (we'll add more if this works)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:27.037349Z","iopub.execute_input":"2025-11-02T12:09:27.037941Z","iopub.status.idle":"2025-11-02T12:09:27.749572Z","shell.execute_reply.started":"2025-11-02T12:09:27.037903Z","shell.execute_reply":"2025-11-02T12:09:27.748863Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Minimal augmentation (we'll add more if this works)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nfrom torch.utils.data import Dataset\n\nclass GingivaDS(Dataset):\n    def __init__(self, df, transform):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        try:\n            img = cv2.imread(row.path)\n            if img is None:\n                raise ValueError(f\"Cannot load: {row.path}\")\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        except:\n            img = np.zeros((cfg.img_size, cfg.img_size, 3), dtype=np.uint8)\n        \n        aug = self.transform(image=img)\n        img_tensor = aug['image']\n        label = torch.tensor(row.label_id, dtype=torch.long)\n        \n        return img_tensor, label\n\nprint(\"‚úÖ Dataset class ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:32.810418Z","iopub.execute_input":"2025-11-02T12:09:32.810736Z","iopub.status.idle":"2025-11-02T12:09:32.817511Z","shell.execute_reply.started":"2025-11-02T12:09:32.810683Z","shell.execute_reply":"2025-11-02T12:09:32.816641Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset class ready\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader\n\ntrain_ds = GingivaDS(train_df, get_transforms(\"train\"))\nval_ds = GingivaDS(val_df, get_transforms(\"val\"))\ntest_ds = GingivaDS(test_df, get_transforms(\"val\"))\n\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=cfg.batch_size,\n    shuffle=True,  \n    num_workers=cfg.num_workers,\n    pin_memory=True,\n    drop_last=False\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=cfg.batch_size,\n    shuffle=False,\n    num_workers=cfg.num_workers,\n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=cfg.batch_size,\n    shuffle=False,\n    num_workers=cfg.num_workers,\n    pin_memory=True\n)\n\nprint(f\"‚úÖ Simple data loaders ready\")\nprint(f\"   Train batches: {len(train_loader)}\")\nprint(f\"   Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:39.237411Z","iopub.execute_input":"2025-11-02T12:09:39.237724Z","iopub.status.idle":"2025-11-02T12:09:39.249746Z","shell.execute_reply.started":"2025-11-02T12:09:39.237673Z","shell.execute_reply":"2025-11-02T12:09:39.249029Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Simple data loaders ready\n   Train batches: 69\n   Val batches: 15\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nimport timm\nimport torch.nn as nn\n\nclass SimpleModel(nn.Module):\n    def __init__(self, backbone_name, num_classes=3, dropout=0.2):\n        super().__init__()\n        \n        # Use pretrained model\n        self.backbone = timm.create_model(\n            backbone_name,\n            pretrained=True,\n            num_classes=num_classes, \n        )\n    \n    def forward(self, x):\n        return self.backbone(x)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SimpleModel(cfg.backbone, num_classes=3, dropout=cfg.dropout)\nmodel = model.to(device)\n\nprint(f\"‚úÖ Simple {cfg.backbone} model on {device}\")\nprint(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:43.485218Z","iopub.execute_input":"2025-11-02T12:09:43.485854Z","iopub.status.idle":"2025-11-02T12:09:53.839445Z","shell.execute_reply.started":"2025-11-02T12:09:43.485828Z","shell.execute_reply":"2025-11-02T12:09:53.838566Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84df498acfdd435dad6086d5092f253f"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Simple resnet50 model on cuda\n   Parameters: 23,514,179\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing)\n\n\noptimizer = Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n\n\nscheduler = ReduceLROnPlateau(\n    optimizer,\n    mode='max',\n    factor=0.5,\n    patience=5,\n    verbose=True,\n    min_lr=1e-7\n)\n\nscaler = torch.cuda.amp.GradScaler()\n\nprint(\"‚úÖ Simple training setup (Cross Entropy + Adam + ReduceLR)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:09:57.551387Z","iopub.execute_input":"2025-11-02T12:09:57.552311Z","iopub.status.idle":"2025-11-02T12:09:57.559873Z","shell.execute_reply.started":"2025-11-02T12:09:57.552279Z","shell.execute_reply":"2025-11-02T12:09:57.558867Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Simple training setup (Cross Entropy + Adam + ReduceLR)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/tmp/ipykernel_122/2700701815.py:23: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\n\ndef train_epoch(model, loader, criterion, optimizer, scaler, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    # Track per-class correct predictions\n    class_correct = {i: 0 for i in range(3)}\n    class_total = {i: 0 for i in range(3)}\n    \n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        with torch.amp.autocast('cuda'):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        # Per-class accuracy\n        for i in range(3):\n            mask = labels == i\n            if mask.sum() > 0:\n                class_total[i] += mask.sum().item()\n                class_correct[i] += (predicted[mask] == labels[mask]).sum().item()\n    \n    epoch_loss = running_loss / len(loader)\n    epoch_acc = 100. * correct / total\n    \n    # Calculate per-class accuracies\n    class_accs = {}\n    for i, name in enumerate(cfg.classes):\n        if class_total[i] > 0:\n            class_accs[name] = 100. * class_correct[i] / class_total[i]\n        else:\n            class_accs[name] = 0.0\n    \n    return epoch_loss, epoch_acc, class_accs\n\n@torch.no_grad()\ndef evaluate(model, loader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    for images, labels in loader:\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = outputs.max(1)\n        \n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.numpy())\n    \n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    accuracy = (all_preds == all_labels).mean() * 100\n    \n    report = classification_report(\n        all_labels, all_preds,\n        target_names=cfg.classes,\n        output_dict=True,\n        zero_division=0\n    )\n    \n    return accuracy, report, all_preds, all_labels\n\nprint(\"‚úÖ Training functions ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:10:02.758210Z","iopub.execute_input":"2025-11-02T12:10:02.758988Z","iopub.status.idle":"2025-11-02T12:10:02.770149Z","shell.execute_reply.started":"2025-11-02T12:10:02.758962Z","shell.execute_reply":"2025-11-02T12:10:02.769102Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Training functions ready\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define directories\nWORK_DIR = cfg.output_dir\nOUTPUT_DIR = \"/kaggle/outputs\"  \nos.makedirs(WORK_DIR, exist_ok=True)\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(\"üíæ Working directory:\", WORK_DIR)\nprint(\"üìÇ Persistent output directory:\", OUTPUT_DIR)\nimport os\nimport shutil\n\n# Define directories\nWORK_DIR = cfg.output_dir\nOUTPUT_DIR = \"/kaggle/outputs\"  # Kaggle's persistent directory\nos.makedirs(WORK_DIR, exist_ok=True)\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(\"üíæ Working directory:\", WORK_DIR)\nprint(\"üìÇ Persistent output directory:\", OUTPUT_DIR)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T12:10:08.093473Z","iopub.execute_input":"2025-11-02T12:10:08.094201Z","iopub.status.idle":"2025-11-02T12:10:08.101107Z","shell.execute_reply.started":"2025-11-02T12:10:08.094173Z","shell.execute_reply":"2025-11-02T12:10:08.100156Z"}},"outputs":[{"name":"stdout","text":"üíæ Working directory: /kaggle/working/gingivitis-model\nüìÇ Persistent output directory: /kaggle/outputs\nüíæ Working directory: /kaggle/working/gingivitis-model\nüìÇ Persistent output directory: /kaggle/outputs\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\nimport time\nimport torch\nimport os\nimport shutil\nfrom collections import defaultdict\nfrom tqdm import tqdm\nfrom datetime import datetime\n\nhistory = defaultdict(list)\nbest_val_acc = 0\npatience_counter = 0\ncheckpoint_interval = 2  # Save every N epochs\n\n# Define directories\nworking_dir = cfg.output_dir\noutput_dir = \"/kaggle/outputs\"  # Persistent storage\nos.makedirs(working_dir, exist_ok=True)\nos.makedirs(output_dir, exist_ok=True)\n\nprint(\"üöÄ Starting SIMPLE training (Auto Save + Auto Overwrite in Kaggle Outputs)\\n\")\nprint(\"=\" * 90)\n\nfor epoch in range(cfg.epochs):\n    epoch_start = time.time()\n    print(f\"\\nüü¢ Starting Epoch {epoch+1}/{cfg.epochs}\")\n    print(\"-\" * 80)\n\n    # ---------------------- TRAIN ----------------------\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    train_bar = tqdm(train_loader, total=len(train_loader), desc=f\"Training Epoch {epoch+1}\", leave=False)\n\n    for batch_idx, (inputs, targets) in enumerate(train_bar):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.cuda.amp.autocast(enabled=True):\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(targets).sum().item()\n        total += targets.size(0)\n\n        avg_loss = running_loss / total\n        acc = 100. * correct / total\n        train_bar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{acc:.2f}%\")\n\n        if batch_idx % 50 == 0:\n            print(f\"üß© [Epoch {epoch+1}] Batch {batch_idx}/{len(train_loader)} | Loss={avg_loss:.4f} | Acc={acc:.2f}%\")\n            import sys; sys.stdout.flush()\n\n    train_loss = running_loss / total\n    train_acc = 100. * correct / total\n\n    # ---------------------- VALIDATE ----------------------\n    val_acc, val_report, _, _ = evaluate(model, val_loader, device)\n    scheduler.step(val_acc)\n\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_acc'].append(val_acc)\n\n    h_recall = val_report['healthy']['recall'] * 100\n    m_recall = val_report['mild']['recall'] * 100\n    s_recall = val_report['severe']['recall'] * 100\n\n    history['healthy_recall'].append(h_recall)\n    history['mild_recall'].append(m_recall)\n    history['severe_recall'].append(s_recall)\n\n    epoch_time = time.time() - epoch_start\n\n    # ---------------------- EPOCH SUMMARY ----------------------\n    print(f\"\\nüìä Epoch {epoch+1} Summary ({epoch_time:.1f}s)\")\n    print(f\"  Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n    print(f\"  Val:   Acc={val_acc:.2f}% | Recalls ‚Üí H={h_recall:.1f}%  M={m_recall:.1f}%  S={s_recall:.1f}%\")\n    print(f\"  LR: {optimizer.param_groups[0]['lr']:.2e}\")\n\n    if epoch >= 5 and (h_recall == 0 or m_recall == 0):\n        print(f\"  ‚ö†Ô∏è WARNING: Some classes still have 0% recall!\")\n\n    # ---------------------- SAVE CHECKPOINT ----------------------\n    if (epoch + 1) % checkpoint_interval == 0:\n        ckpt_path = os.path.join(working_dir, f\"checkpoint_epoch{epoch+1}.pth\")\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'scaler_state_dict': scaler.state_dict(),\n            'val_acc': val_acc\n        }, ckpt_path)\n        print(f\"üíæ Saved checkpoint at epoch {epoch+1}\")\n\n    # ---------------------- SAVE BEST MODEL ----------------------\n    if val_acc > best_val_acc:\n        improvement = val_acc - best_val_acc\n        best_val_acc = val_acc\n        patience_counter = 0\n\n        best_model_path = os.path.join(working_dir, \"best_model.pth\")\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"  ‚úÖ New best model saved (+{improvement:.2f}%)\")\n\n        # ‚úÖ Overwrite best model in persistent output\n        output_best_path = os.path.join(output_dir, \"best_model.pth\")\n        shutil.copy(best_model_path, output_best_path)\n        print(f\"  üìÇ Overwritten persistent best model ‚Üí {output_best_path}\")\n\n    else:\n        patience_counter += 1\n        print(f\"  No improvement ({patience_counter}/{cfg.patience})\")\n\n    print(\"-\" * 80)\n\n    # ---------------------- EARLY STOP ----------------------\n    if patience_counter >= cfg.patience:\n        print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch+1}\")\n        break\n\n# ---------------------- FINAL SAVE ----------------------\nfinal_model_path = os.path.join(working_dir, \"final_model.pth\")\ntorch.save(model.state_dict(), final_model_path)\n\n# ‚úÖ Overwrite persistent final model\noutput_final_path = os.path.join(output_dir, \"final_model.pth\")\nshutil.copy(final_model_path, output_final_path)\n\nprint(f\"\\n‚úÖ Training complete! Best Val Acc: {best_val_acc:.2f}%\")\nprint(f\"üíæ Final model saved at: {final_model_path}\")\nprint(f\"üìÇ Overwritten persistent final model ‚Üí {output_final_path}\")\nprint(\"=\" * 90)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os; print(os.listdir(\"/kaggle/outputs\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}